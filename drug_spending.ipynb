{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medicaid spending on prescription drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_states = list(us.states.mapping('abbr', 'name').values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store year along with the data from each sheet\n",
    "# So we can add this as a column later\n",
    "# Unnecessary for 2016 data\n",
    "\n",
    "expenditures_16 = (pd.read_excel(\"data/medicaid_spending/FY_2016_Financial_Management_Data.xlsx\", usecols=[0, 2, 4, 10]))\n",
    "expenditures_15 = (2015, pd.read_excel(\"data/medicaid_spending/FY 2015 NET EXPENDITURES.xlsx\", header=6, sheetname=None, usecols=[0, 1]))\n",
    "expenditures_14 = (2014, pd.read_excel(\"data/medicaid_spending/FMR Net Expenditures FY14.xlsx\", header=6, sheetname=None, usecols=[0, 1]))\n",
    "expenditures_13 = (2013, pd.read_excel(\"data/medicaid_spending/FMR Net Expenditures FY13.xlsx\", header=6, sheetname=None, usecols=[0, 1]))\n",
    "expenditures_12 = (2012, pd.read_excel(\"data/medicaid_spending/FMR Net Expenditures FY12.xlsx\", header=6, sheetname=None, usecols=[0, 1]))\n",
    "expenditures_06_11 = pd.read_excel(\"data/medicaid_spending/NetExpenditure02through11.xlsx\", header=None, skiprows=4, usecols=[0, 1], sheetname=[\"2006\", \"2007\", \"2008\", \"2009\", \"2010\", \"2011\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make an array of the datasets we want to join\n",
    "expenditures_12_15 = [expenditures_15, expenditures_14, expenditures_13, expenditures_12]\n",
    "\n",
    "# Empty array to hold the final dataframes\n",
    "extracted_sheets = []\n",
    "for year, data in expenditures_12_15:\n",
    "    \n",
    "    # Filter sheets that have \"MAP\" in the value.\n",
    "    wanted_sheets = [(sheet_name, sheet) for sheet_name, sheet in data.items() if sheet_name.startswith('MAP')]\n",
    "    \n",
    "    # If we don't find any sheets that have MAP, then use all available sheets\n",
    "    # This is to handle 2012 dataset\n",
    "    if not wanted_sheets:\n",
    "        wanted_sheets = data.items()\n",
    "\n",
    "    # Create a list of sheet names (in this case that's the state names)\n",
    "    sheet_names = [sheet_name for sheet_name, sheet in wanted_sheets]\n",
    "    \n",
    "    # Create a list of all the sheets corresponding to each name above\n",
    "    sheets = [sheet for sheet_name, sheet in wanted_sheets]\n",
    "    \n",
    "    # Remove MAP from sheet name if it exists\n",
    "    sheet_names = [sheet_name.split('-')[-1] for sheet_name in sheet_names]\n",
    "    \n",
    "    # Combine all the sheets and use the sheet_names to add a state column in the final dataset\n",
    "    all_states = pd.concat(sheets, keys=sheet_names)\n",
    "    \n",
    "    # Add a YEAR column to signify the year for the sheets being added\n",
    "    all_states['Year'] = year\n",
    "    \n",
    "    # Add them to an array so they can be concatenated later.\n",
    "    extracted_sheets.append(all_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Empty array to hold the final dataframes for 2006 - 2011\n",
    "all_06_11_data = []\n",
    "\n",
    "# Iterate through the file, the sheet name is the year.\n",
    "for year, data in expenditures_06_11.items():\n",
    "    \n",
    "    # Identify rows that deliniate the tables (each containing a state) or contains one of the summary table names\n",
    "    boundary_rows = data[0].isin(list_of_states + ['All States', 'National Totals'])\n",
    "    boundary_indices = data[boundary_rows].index\n",
    "    \n",
    "    # Place holder to hold the data from the curent iteration\n",
    "    states = []\n",
    "    \n",
    "    # Each boundary indicates the start of a table, each table contains data for a state\n",
    "    for i,item in enumerate(boundary_indices):\n",
    "        start = item\n",
    "        if i+1 < len(boundary_indices): end = boundary_indices[i+1]\n",
    "        else: end = None # Get the rest of the dataframe it's the last slice\n",
    "\n",
    "        # Slice the current table (state) out of the main dataset\n",
    "        current_dataset = data.iloc[start:end]\n",
    "        \n",
    "        # Replace columns with whitespace into Null value (NA)\n",
    "        current_dataset = current_dataset.replace(r'^\\s+$', np.nan, regex=True)\n",
    "        \n",
    "        # Remove rows where all columns are null\n",
    "        current_dataset = current_dataset.dropna(how='all')\n",
    "        \n",
    "        # Get the name of the state from the first column of the first row\n",
    "        state_name = current_dataset.iloc[0][0]\n",
    "        \n",
    "        # If the state name is a valid state then we keep the table (ignore summary statistics)\n",
    "        if state_name in list_of_states:\n",
    "            current_dataset['State'] = state_name\n",
    "            current_dataset.columns = ['Service Category', 'Total Computable', 'State']\n",
    "            current_dataset = current_dataset[-current_dataset['Service Category'].isin([state_name, 'Service Category'])]\n",
    "            states.append(current_dataset)\n",
    "    \n",
    "    all_states_current_year = pd.concat(states)\n",
    "    all_states_current_year['Year'] = year\n",
    "    all_06_11_data.append(all_states_current_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate all the sheets from all the years into a big dataframe with a state and year column\n",
    "medicaid_rebates = pd.concat(all_06_11_data + extracted_sheets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interested_categories = (\"Drug Rebate Offset - National\",\n",
    "\"Drug Rebate Offset - State Sidebar Agreement\",\n",
    "\"MCO - National Agreement\",\n",
    "\"MCO - State Sidebar Agreement\",\n",
    "\"Increased ACA OFFSET - Fee for Service\",\n",
    "\"Increased ACA OFFSET - MCO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "medicaid_drug_rebates = medicaid_rebates[medicaid_rebates['Service Category'].isin(interested_categories)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "medicaid_drug_rebates.to_excel(\"data/medicaid_drug_rebates.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
